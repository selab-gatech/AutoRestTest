# ===========================
# AutoRestTest Configuration
# ===========================

[spec]
# Relative path from the project root to the OpenAPI specification file.
# Only .yaml and .json are supported; file MUST be OpenAPI 3.0.
# location = "specs/original/oas/ohsome.yaml"
location = "aratrl-openapi/market2.yaml"

# Maximum times a circular/self-reference may appear in the resolution stack.
# A value of 1 means an element may be referred to exactly once before triggering the handler.
recursion_limit = 1

# Validate the OpenAPI spec strictly (errors will abort) when true; allow lenient parsing when false.
strict_validation = false

[llm]
# LLM engine used for Value Agent (and optional Header Agent) generation.
# Supports any model from an OpenAI-API compatible provider (OpenAI, OpenRouter, Azure, local models, etc.).
# Must support JSON mode.
engine = "google/gemini-2.5-flash-lite-preview-09-2025"

# Sampling temperature for creative generations (0.0 = deterministic, higher = more random).
creative_temperature = 1

# Sampling temperature for strict/repair flows (e.g., retries, JSON fixes).
strict_temperature = 1

# Base URL for the LLM API. Supports any OpenAI-API compatible endpoint.
# Examples: "https://api.openai.com/v1", "https://openrouter.ai/api/v1", "http://localhost:1234/v1"
api_base = "https://openrouter.ai/api/v1"

# Maximum tokens for LLM response. Set to -1 to omit and use provider default.
max_tokens = 20000

[agent]
# Max number of optional parameters per combination (required params always included).
max_combinations = 12

# Hard cap on total combinations per operation to bound memory usage.
max_total_combinations = 3000

# Base sample count at size=1; decays for larger sizes (size=5 gets ~60 samples).
base_samples_per_size = 200

# Seed for reproducible combination sampling. Change to get different random samples.
combination_seed = 42

[agent.value]
# Enable parallel value table generation using thread pool.
# Set to false to use sequential DFS generation.
parallelize = true

# Number of worker threads for parallel generation (ignored if parallelize = false).
max_workers = 16

[agents.header]
# Whether to enable the Header Agent (uses Basic tokens). Only helpful for APIs requiring such auth.
enabled = false

[cache]
# Use the cached Semantic Operation Dependency Graph produced by a prior run.
use_cached_graph = true

# Use the cached Q-table(s) for the Value Agent (and optional Header Agent) to avoid re-running the LLM.
use_cached_table = false

# Tip: Set either cache flag to false if you changed graph construction or table generation logic to regenerate the cache.

[q_learning]
# Q-learning agent hyperparameters.
learning_rate = 0.1        # alpha
discount_factor = 0.9       # gamma
max_exploration = 1         # epsilon; decays over time to 0.1

[request_generation]
# Controls the request generation process.
# Duration for generation in seconds.
time_duration = 1200

# Probability of mutating request parameters during generation.
mutation_rate = 0.2

[api]
# By default, the API URL is extracted from the OpenAPI specification's "servers" field.
# Set override_url to true to use the custom host and port instead.
override_url = false
host = "localhost"
port = 8080

[custom_headers]
# Static headers to include with every request.
# Supports environment variable interpolation using ${VAR_NAME} syntax.
# Example:
# Authorization = "Bearer ${ACCESS_TOKEN}"
# X-API-Key = "static-value"
